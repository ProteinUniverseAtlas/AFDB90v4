{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d8f37d-02b8-4a9a-8294-85079efb8b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a077f54-61e4-42ee-a3ef-28ee6a003189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gensim.models import FastText\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0639867c-4591-4d9a-a213-675fabe9dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_jobs = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a923366-8e77-4792-9d52-6dc128c564bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predicting outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059db816-2da9-42aa-b4b6-a51959da5269",
   "metadata": {},
   "source": [
    "To detect structural outliers we first generate shape-mers for the ProteinNet proteins and AFDBv490 proteins using the code in `make_shapemers.py` - these are `data/proteinnet_shapemers.txt` and `data/afdb90_shapemers.txt`. \n",
    "\n",
    "Then, below, we train a FastText model on the ProteinNet shapemers followed by an IsolationForest model on the FastText sentence vectors. These trained models are used to predict outliers for the AFDBv490 protein shape-mer representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1611c90e-8ad1-42d6-b71e-e89116c2e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def documents_to_keys_corpus(documents):\n",
    "    keys_corpus = (line.strip().split(\"\\t\") for corpus_file in documents for line in tqdm(open(corpus_file)) if\n",
    "                   len(line.strip().split(\"\\t\")) == 2)\n",
    "    keys, corpus = itertools.tee(keys_corpus)\n",
    "    keys = [k[0] for k in keys]\n",
    "    corpus = (k[1] for k in corpus)\n",
    "    return keys, corpus\n",
    "\n",
    "\n",
    "def vectorizer_from_documents(documents, fasttext_model_file, corpus_file, num_jobs=100):\n",
    "    keys, corpus = documents_to_keys_corpus(documents)\n",
    "    with open(corpus_file, \"w\") as f:\n",
    "        for shapemers in corpus:\n",
    "            f.write(\" \".join(f'{int(s):010b}' for s in shapemers.split()) + \"\\n\")\n",
    "    vectorizer = FastText(vector_size=1024, window=16, min_count=1, workers=num_jobs)\n",
    "    vectorizer.build_vocab(corpus_file=corpus_file)\n",
    "    vectorizer.train(\n",
    "        corpus_file=corpus_file, epochs=vectorizer.epochs,\n",
    "        total_examples=vectorizer.corpus_count, total_words=vectorizer.corpus_total_words,\n",
    "    )\n",
    "    vectorizer.save(str(fasttext_model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b40af22-7be5-4a75-8c2d-135dabf765eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_from_documents([\"data/proteinnet_shapemers.txt\"], \n",
    "                          \"data/fasttext.mdl\", \n",
    "                          \"data/fasttext_corpus.txt\", num_jobs=num_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a85826-a21d-46dd-a662-c4f33ce1db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = FastText.load(\"data/fasttext.mdl\", mmap='r').wv\n",
    "outlier_detector = IsolationForest(n_jobs=num_jobs, n_estimators=1000,\n",
    "                                   max_features=0.5, contamination=0.1,\n",
    "                                   verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6936ae29-fdf9-4265-84f8-90aa1c851e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vector(document):\n",
    "    return vectorizer.get_sentence_vector([f'{int(s):010b}' for s in document.split()])\n",
    "\n",
    "def vectorize(corpus, num_jobs, total):\n",
    "    with Pool(processes=num_jobs) as pool:\n",
    "        matrix = list(tqdm(pool.imap(get_sentence_vector,\n",
    "                                     corpus),\n",
    "                           total=total))\n",
    "    return np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c32eee-afde-4840-a6d4-cf24f612433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, corpus = documents_to_keys_corpus([\"data/proteinnet_shapemers.txt\"])\n",
    "matrix = vectorize(corpus, num_jobs, len(keys))\n",
    "outlier_detector.fit(matrix)\n",
    "with open(\"data/isolation_forest.pkl\", \"wb\") as f:\n",
    "    pickle.dump(outlier_detector, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4748607e-09c2-42ba-bb14-a5986128b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = Path(\"data/outlier_results\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "keys, corpus = documents_to_keys_corpus([Path(\"data/afdb90_shapemers.txt\")])\n",
    "print(\"Vectorizing\")\n",
    "matrix = np.array(\n",
    "    [vectorizer.get_sentence_vector([f'{int(s):010b}' for s in document.split()]) for document in tqdm(corpus)])\n",
    "print(\"Predicting\")\n",
    "scores = outlier_detector.decision_function(matrix)\n",
    "print(\"Saving\")\n",
    "with open(output_folder / f\"afdb90_outliers.txt\", \"w\") as f:\n",
    "    for key, score in zip(keys, scores):\n",
    "        f.write(f\"{key}\\t{score:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a8a8a6-8f99-4769-8944-2229a37809b5",
   "metadata": {},
   "source": [
    "# Outlier Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219e4ebe-b526-401f-bb87-a62657ec3e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import extract_uniprot\n",
    "import extract_interpro\n",
    "\n",
    "MONGO_HOST = \"10.1.0.202\"\n",
    "MONGO_PORT = 30077\n",
    "\n",
    "UNIPROT_DB = extract_uniprot.uniprot_extractor(mongo_host=MONGO_HOST, mongo_port=MONGO_PORT)\n",
    "INTERPRO_DB = extract_interpro.interpro_db_diggested(mongo_host=MONGO_HOST, mongo_port=MONGO_PORT)\n",
    "\n",
    "\n",
    "def get_data(uniprot_ids):\n",
    "    uniprot_ids = [x.split(\"-\")[0] for x in uniprot_ids]\n",
    "    uniprot_collection = UNIPROT_DB.col.find({'_id': {\"$in\": uniprot_ids}})\n",
    "    interpro_collection = INTERPRO_DB.col.find({'_id': {\"$in\": uniprot_ids}})\n",
    "    data = {}\n",
    "    for u_entry in tqdm(uniprot_collection):\n",
    "        data[u_entry[\"_id\"] + \"-F1\"] = u_entry[\"data\"]\n",
    "    for i_entry in tqdm(interpro_collection):\n",
    "        key = i_entry[\"_id\"] + \"-F1\"\n",
    "        if key not in data:\n",
    "            data[key] = {}\n",
    "        data[key][\"interpro\"] = i_entry[\"data\"]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f671a-675d-4815-b44f-5a9fd781caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = pnd.read_csv(\"data/data.csv\", index_col=0)\n",
    "to_darkness = dict(zip(data_file[\"AF2_longest_best70\"], data_file[\"FULL_noDUF\"]))\n",
    "to_length = dict(zip(data_file[\"AF2_longest_best70\"], data_file[\"AF2_longest_best70_len\"]))\n",
    "to_outlier = {}\n",
    "with open(\"data/afdb90_outliers.txt\") as f:\n",
    "    for line in tqdm(f):\n",
    "        key, score = line.strip().split(\"\\t\")\n",
    "        to_outlier[key] = float(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e76cede-5636-4695-8068-63c9ac9f36b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_data = get_data([k for k in to_outlier if to_outlier[k] < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c147cbf-1fc4-492f-89d2-5afee0f207d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tonb_proteins = []\n",
    "for k in outlier_data:\n",
    "    if \"interpro\" in outlier_data[k] and any(\"TonB-dependent receptor-like\" in i[0] for i in outlier_data[k][\"interpro\"]):\n",
    "        tonb_proteins.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df7d03-ec7e-40ed-b04a-a2438c8e9ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_color = \"#634248\"\n",
    "inlier_color = \"#758a5e\"\n",
    "background_color = '#F2F2F2'\n",
    "purple = '#57257F'\n",
    "inlier_threshold = 0.115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ca5a5-7902-4e0e-bef8-00511b268322",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_diversity = {}\n",
    "with open(\"data/afdb90_shapemers.txt\") as f:\n",
    "    for line in tqdm(f):\n",
    "        key, shapemers = line.strip().split(\"\\t\")\n",
    "        shapemers = list(map(int, shapemers.split()))\n",
    "        to_diversity[key] = len(set(shapemers)) / len(shapemers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ca0703-7205-4461-add7-3063d9d9fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(10, 10), sharey=True)\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        ax[i][j].set_facecolor(background_color)\n",
    "        \n",
    "nbins = np.arange(0, 105, 5)\n",
    "n = list(range(0,21,5))\n",
    "l = list(range(0,101,25))\n",
    "heights, _ = np.histogram([to_darkness[k[:-3]] for k in to_outlier if to_outlier[k] < 0], bins = nbins)\n",
    "heights = heights * 100/sum(heights)\n",
    "x = list(range(len(heights)))\n",
    "y = list(heights)\n",
    "ax[0][0].bar(x, y, 1, align=\"edge\", \n",
    "         label=\"Outliers\", color=outlier_color, edgecolor=\"black\");\n",
    "ax[0][0].set_xlabel(\"Functional brightness (%)\")\n",
    "ax[0][0].set_xticks(n, l)\n",
    "\n",
    "heights, _ = np.histogram([to_darkness[k[:-3]] for k in to_outlier if to_outlier[k] > inlier_threshold], bins = nbins)\n",
    "heights = heights * 100/sum(heights)\n",
    "x = list(range(len(heights)))\n",
    "y = list(heights)\n",
    "ax[1][0].bar(x, y, 1, align=\"edge\", \n",
    "         label=\"Inliers\", color=inlier_color, edgecolor=\"black\");\n",
    "ax[1][0].set_xlabel(\"Functional brightness (%)\")\n",
    "ax[1][0].set_xticks(n, l)\n",
    "\n",
    "\n",
    "nbins = np.arange(0, 1.1, 0.1)\n",
    "n = [(i, f\"{nbins[i]:.1f}\") for i in range(len(nbins)) if i%2==0]\n",
    "heights, _ = np.histogram([to_diversity[k[:-3]] for k in to_outlier if to_outlier[k] < 0], bins = nbins)\n",
    "heights = heights * 100/sum(heights)\n",
    "x = list(range(len(heights)))\n",
    "y = list(heights)\n",
    "ax[0][1].bar(x, y, 1, align=\"edge\", \n",
    "         label=\"Outliers\", color=outlier_color, edgecolor=\"black\");\n",
    "ax[0][1].set_xlabel(\"$Diversity=\\\\frac{|\\{shape-mers\\}|}{|shape-mers|}$\")\n",
    "ax[0][1].set_xticks([x[0] for x in n], [x[1] for x in n])\n",
    "\n",
    "heights, _ = np.histogram([to_diversity[k[:-3]] for k in to_outlier if to_outlier[k] > inlier_threshold], bins = nbins)\n",
    "heights = heights * 100/sum(heights)\n",
    "x = list(range(len(heights)))\n",
    "y = list(heights)\n",
    "ax[1][1].bar(x, y, 1, align=\"edge\", \n",
    "         label=\"Inliers\", color=inlier_color, edgecolor=\"black\");\n",
    "ax[1][1].set_xlabel(\"$Diversity=\\\\frac{|\\{shape-mers\\}|}{|shape-mers|}$\")\n",
    "ax[1][1].set_xticks([x[0] for x in n], [x[1] for x in n])\n",
    "\n",
    "ax[0][0].set_title(\"A\", fontsize=15, loc=\"left\")\n",
    "ax[0][1].set_title(\"Outliers\", fontsize=15)\n",
    "ax[1][0].set_title(\"B\", fontsize=15, loc=\"left\")\n",
    "ax[1][1].set_title(\"Inliers\", fontsize=15)\n",
    "\n",
    "nbins = np.arange(0, 2250, 250)\n",
    "n = [(i, nbins[i]) for i in range(len(nbins)) if i%2==0]\n",
    "heights, _ = np.histogram([to_length[k[:-3]] for k in to_outlier if to_outlier[k] < 0], bins = nbins)\n",
    "heights = heights * 100/sum(heights)\n",
    "x = list(range(len(heights)))\n",
    "y = list(heights)\n",
    "ax[0][2].bar(x, y, 1, align=\"edge\", \n",
    "         label=\"Outliers\", color=outlier_color, edgecolor=\"black\");\n",
    "ax[0][2].set_xlabel(\"Protein length\")\n",
    "ax[0][2].set_xticks([x[0] for x in n], [x[1] for x in n])\n",
    "\n",
    "heights, _ = np.histogram([to_length[k[:-3]] for k in to_outlier if to_outlier[k] > inlier_threshold], bins = nbins)\n",
    "heights = heights * 100/sum(heights)\n",
    "x = list(range(len(heights)))\n",
    "y = list(heights)\n",
    "ax[1][2].bar(x, y, 1, align=\"edge\", \n",
    "         label=\"Inliers\", color=inlier_color, edgecolor=\"black\");\n",
    "ax[1][2].set_xlabel(\"Protein length\")\n",
    "ax[1][2].set_xticks([x[0] for x in n], [x[1] for x in n])\n",
    "\n",
    "ax[0][0].set_ylabel(\"% of outliers\")\n",
    "ax[1][0].set_ylabel(\"% of inliers\")\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.3)\n",
    "plt.yticks(np.arange(0, 110, 10))\n",
    "plt.savefig(\"outliers.pdf\", dpi=2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometricus",
   "language": "python",
   "name": "geometricus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
