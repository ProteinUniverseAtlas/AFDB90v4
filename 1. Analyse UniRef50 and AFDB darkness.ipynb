{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "strange-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-andrew",
   "metadata": {},
   "source": [
    "# 1. Analyse the darkness content of UniRef50 and AlphaFold DB (v4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-joining",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n",
    "First, run:\n",
    "\n",
    "`python3 scripts/AFDBv4_pLDDT_analysis.py UniRef50`\n",
    "\n",
    "This will generate the file `data_generated/AFDBv4_pLDDT_diggestion.csv`. The corresponding for the AFDB90v4 paper, is `data_generated/AFDBv4_pLDDT_diggestion_UniRef50_2023-02-01.csv`, which we load in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fatal-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "indata = 'data_generated/AFDBv4_pLDDT_diggestion_UniRef50_2023-02-01.csv'\n",
    "indata = pd.read_csv(indata)\n",
    "indata = indata.sort_values(by='unirefID')\n",
    "indata = indata.set_index(\"unirefID\")\n",
    "indata = indata[:-1]\n",
    "indata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "indata['darkness_bins'] = pd.cut(indata['FULL_noDUF'].astype(float), bins=[i for i in range(0, 105, 5)], include_lowest=True)\n",
    "indata['median_Evidence'] = indata['median_Evidence'].fillna(0)\n",
    "indata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-importance",
   "metadata": {},
   "source": [
    "To add DUF counts into the dataframe, run `python3 scripts/AFDBv4_DUF_analysis_dark.py UniRef50`, which will generate the `generated_data/AFDBv4_DUF_dark_diggestion_UniRef50.csv`\n",
    "\n",
    "For the AFDB90v4 paper, the precomupted file is `data_generated/AFDBv4_DUF_dark_diggestion_UniRef50_2023-02-06.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get DUF distribution of all darks and merge with the data\n",
    "\n",
    "duf_dark_data = 'data_generated/AFDBv4_DUF_dark_diggestion_UniRef50_2023-02-06.csv'\n",
    "duf_dark_data = pd.read_csv(duf_dark_data)\n",
    "duf_dark_data = duf_dark_data.sort_values(by='unirefID')\n",
    "duf_dark_data = duf_dark_data.set_index(\"unirefID\")\n",
    "duf_dark_data = duf_dark_data[:-1]\n",
    "\n",
    "indata = pd.concat([indata, duf_dark_data], axis=1)\n",
    "indata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-qualification",
   "metadata": {},
   "source": [
    "## 1.2. Make histogram at different pLDDT cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = ['Full', 'AFDB', 'AFDB70', 'AFDB90']\n",
    "panel = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "fig, ax = plt.subplots(1, len(panel), figsize=(2.5*len(panel), 3))\n",
    "percentage_dufs = []\n",
    "\n",
    "for j, mode in enumerate(modes):\n",
    "    if mode == 'Full':\n",
    "        tmp = indata\n",
    "    if 'AFDB' in mode:\n",
    "        tmp = indata.loc[indata.nAF2.astype(float) > 0]\n",
    "        if len(mode.split('AFDB')[-1]) > 0:\n",
    "            cut = int(mode.split('AFDB')[-1])\n",
    "            tmp = tmp.loc[tmp.AF2_longest_best70_pLDDT.astype(float) >= cut]\n",
    "    \n",
    "    h,_ = np.histogram(tmp.FULL_noDUF.astype(float), bins=[i for i in range(0, 105, 5)])\n",
    "    n_dark = h[0]\n",
    "    h = h*100/sum(h)\n",
    "\n",
    "    colors = ['#57257F']\n",
    "    for i in range(len(h)-2):\n",
    "        colors.append('silver')\n",
    "    colors.append('white')\n",
    "\n",
    "    x = list(range(len(h)))\n",
    "    y = list(h)\n",
    "\n",
    "    ax[j].bar(x,y,1, align='edge', color=colors, edgecolor='k')\n",
    "    ax[j].set_facecolor('#F2F2F2')\n",
    "    ax[j].set_xticks(range(0,21,5))\n",
    "    ax[j].set_xticklabels(range(0,101,25))\n",
    "    ax[j].set_ylabel('% of UniRef50 clusters')\n",
    "    ax[j].set_xlabel('Functional Brightness (%)')\n",
    "    \n",
    "    ax[j].title.set_text('{} {}'.format(panel[j], mode))\n",
    "\n",
    "    ax[j].set_ylim(0,100)\n",
    "    \n",
    "    percentage_dark = round(h[0])\n",
    "    ax[j].text(-0.1, percentage_dark+1, '{}%'.format(percentage_dark),\n",
    "               verticalalignment='bottom', horizontalalignment='left',\n",
    "               color='#57257F', fontsize=9)\n",
    "    \n",
    "    uniprot_n_dark = sum(tmp.loc[tmp.FULL_noDUF.astype(float) <=5].nACCs.astype(float))\n",
    "    print(mode, 'n =', len(tmp), 'n_dark =', n_dark, 'uniprot_n_dark =', uniprot_n_dark, '% uniprot =', uniprot_n_dark*100/sum(tmp.nACCs.astype(float)))\n",
    "\n",
    "    uniref_n_dark = sum(tmp.loc[tmp.FULL_noDUF.astype(float) <=5].nUniRef100.astype(float))\n",
    "    print(mode, 'n =', len(tmp), 'n_dark =', n_dark, 'uniref100_n_dark =', uniref_n_dark, '% uniref100 =', uniref_n_dark*100/sum(tmp.nUniRef100.astype(float)))\n",
    "    \n",
    "    percentage_duf = len(tmp.loc[tmp.Has_duf == 1])*100/len(tmp.loc[tmp.FULL_noDUF.astype(float) <=5])\n",
    "    print('% UniRef50 dark with dufs =', percentage_duf)\n",
    "    print()\n",
    "    \n",
    "    percentage_dufs.append(percentage_duf)\n",
    "\n",
    "ax[j+1].bar(panel[:-1],percentage_dufs,1, align='center', color=['#57257F' for i in modes], edgecolor='k')\n",
    "ax[j+1].set_facecolor('#F2F2F2')\n",
    "ax[j+1].set_ylabel('% of dark clusters with DUF')\n",
    "ax[j+1].set_xlabel('Set')\n",
    "ax[j+1].title.set_text('({}) DUF content'.format(panel[j+1]))\n",
    "ax[j+1].set_ylim(0,0.2)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/AFDBv4_uniref50_histogram_dark_content.pdf')\n",
    "plt.savefig('plots/AFDBv4_uniref50_histogram_dark_content.png', dpi=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('brightness vs size Correlation {}:'.format(mode), scipy.stats.pearsonr(indata['FULL_noDUF'], indata['nUniRef100'])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "indata.groupby(['darkness_bins'])['nUniRef100'].agg([np.mean, np.std, np.median])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-veteran",
   "metadata": {},
   "source": [
    "# 2. Define AFDB90 set and collect all associated sequences from previously contructed mongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "AFDB90 = indata.loc[indata.AF2_longest_best70_pLDDT.astype(float) >= 90]\n",
    "AFDB90.to_csv('data_generated/AFDB90v4_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbuilder_path = None # change accordingly\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(dbuilder_path)\n",
    "\n",
    "import extract_uniprot     as uniprot\n",
    "\n",
    "MONGO_HOST = \"10.1.0.202\"\n",
    "MONGO_PORT = 30077\n",
    "\n",
    "uniprot_db   = uniprot.uniprot_extractor(mongo_host = MONGO_HOST, mongo_port = MONGO_PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfasta = 'data_generated/AFDBv4_90.fasta'\n",
    "\n",
    "count = 0\n",
    "step = 100000\n",
    "\n",
    "target_ids =  [i.split('_')[1] for i in AFDB90.index]\n",
    "n_entries = len(target_ids)\n",
    "\n",
    "chuncks   = [target_ids[i:i+step] if i+step < len(target_ids) else target_ids[i:] for i in range(0, n_entries, step)]\n",
    "collected_ids = []\n",
    "\n",
    "print('Getting sequences for {} chuncks'.format(len(chuncks)))\n",
    "      \n",
    "with open(outfasta, 'w') as out:\n",
    "    for i, chunck in enumerate(chuncks):\n",
    "        documents = uniprot_db.col.find({'_id': {'$in': chunck}})\n",
    "        for doc in documents:\n",
    "            out.write('>{}\\n{}\\n'.format(doc['_id'], doc['data']['SEQ']))\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
